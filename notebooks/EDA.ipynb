{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no secrets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY\")\n",
    "\n",
    "if access_key:\n",
    "    print(access_key)\n",
    "else:\n",
    "    print(\"no secrets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "appName() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\mlops_pharma\\physician_conversion_mlops\\notebooks\\EDA.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mappName()\u001b[39m.\u001b[39mgetOrCreate()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdbutils\u001b[39;00m \u001b[39mimport\u001b[39;00m DBUtils\n",
      "\u001b[1;31mTypeError\u001b[0m: appName() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName().getOrCreate()\n",
    "\n",
    "from pyspark.dbutils import DBUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# AWS credentials and region\n",
    "aws_access_key_id = 'AKIAWLK2YUVDNAFVONGF'\n",
    "aws_secret_access_key = '40H9W8ba7BIX4naNyP4bR1qhs73ETFC8nMs52QrY'\n",
    "aws_region = 'ap-south-1'  # Replace with your desired AWS region\n",
    "\n",
    "# S3 bucket and file details\n",
    "bucket_name = 'pharma-physician-conversion'\n",
    "file_key = 'Input_data/Input_data.csv'\n",
    "\n",
    "# Initialize a Boto3 S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, region_name=aws_region)\n",
    "\n",
    "# Download the file from S3\n",
    "s3.download_file(bucket_name, file_key, 'df_input.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the downloaded file into a pandas DataFrame\n",
    "\n",
    "f = pd.read_csv('df_input.csv')\n",
    "\n",
    "# Now you can work with the DataFrame (e.g., print the first few rows)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\mlops_pharma\\physician_conversion_mlops\\notebooks\\EDA.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m BytesIO\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39muuid\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from io import BytesIO\n",
    "import uuid\n",
    "from pyspark.dbutils import DBUtils\n",
    "\n",
    "#useful functions\n",
    "from physician_conversion_mlops.common import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_data():\n",
    "        def load_data_from_s3(self):\n",
    "\n",
    "                # AWS credentials and region\n",
    "                aws_access_key_id = self.conf['s3'][aws_access_key_id]\n",
    "                aws_secret_access_key = self.conf['s3'][aws_secret_access_key]\n",
    "                aws_region = self.conf['s3'][aws_region]\n",
    "                bucket_name = self.conf['s3'][bucket_name]\n",
    "                file_path = self.conf['s3'][file_path]\n",
    "        \n",
    "                print(\"Secret key and access key was read\")\n",
    "\n",
    "                spark = SparkSession.builder.appName(\"CSV Loading Example\").getOrCreate()\n",
    "                dbutils = DBUtils(spark)\n",
    "                \n",
    "                #encoded_secret_key = urllib.parse.quote(secret_key,safe=\"\")\n",
    "\n",
    "                bucket_name = self.conf['s3']['bucket_name']\n",
    "                mount_name = self.conf['dbfs']['mount_name']\n",
    "\n",
    "                url = 's3a://%s:%s@%s' %(aws_access_key_id, aws_secret_access_key, bucket_name)\n",
    "\n",
    "                try:\n",
    "                        dbutils.fs.mount(url,mount_name)\n",
    "                \n",
    "                except:\n",
    "                        pass\n",
    "\n",
    "                spark_data = spark.read.format('csv')\\\n",
    "                .option('header','true')\\\n",
    "                .option('inferschema','true')\\\n",
    "                .load(self.conf['dbfs']['file_name'])\n",
    "                \n",
    "                return spark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_data_from_s3() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\mlops_pharma\\physician_conversion_mlops\\notebooks\\EDA.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m load_data_from_s3()\n",
      "\u001b[1;31mTypeError\u001b[0m: load_data_from_s3() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "df = load_data.load_data_from_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'physician_conversion_mlops'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\mlops_pharma\\physician_conversion_mlops\\notebooks\\EDA.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#useful functions\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mphysician_conversion_mlops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m Task\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mphysician_conversion_mlops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mlops_pharma/physician_conversion_mlops/notebooks/EDA.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#pyspark and feature store \u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'physician_conversion_mlops'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#useful functions\n",
    "from physician_conversion_mlops.common import Task\n",
    "\n",
    "from physician_conversion_mlops.utils import utils\n",
    "\n",
    "#pyspark and feature store \n",
    "from pyspark.dbutils import DBUtils\n",
    "from databricks.feature_store import feature_table, FeatureLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from demo_project.common import Task\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import boto3\n",
    "import urllib\n",
    "import pickle\n",
    "from pyspark.sql import SparkSession\n",
    "from io import BytesIO\n",
    "from databricks.feature_store.online_store_spec import AmazonDynamoDBSpec\n",
    "import uuid\n",
    "\n",
    "from databricks import feature_store\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from databricks.feature_store import feature_table, FeatureLookup\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from pyspark.dbutils import DBUtils"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
